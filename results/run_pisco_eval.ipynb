{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:50:58.021573Z",
     "start_time": "2024-12-16T16:50:57.932419500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8981640befadcae7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART toolbox not setup properly or not available\n"
     ]
    }
   ],
   "source": [
    "from utils import basic, eval, vis"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:50:59.928818400Z",
     "start_time": "2024-12-16T16:50:58.023572100Z"
    }
   },
   "id": "987f4420af49a84a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "checkpoint_path = (\"results/checkpoints\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:50:59.929820800Z",
     "start_time": "2024-12-16T16:50:59.920813900Z"
    }
   },
   "id": "4b252c4cec746ece",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_state=4999\n",
    "sub = \"S10\"\n",
    "slice = 0\n",
    "acc_factors = [104] # [15, 26, 52, 104]\n",
    "lambd = [0.15]\n",
    "#\n",
    "# ### Define all models to compare\n",
    "for acc_factor, l in zip(acc_factors, lambd):\n",
    "    model = {}\n",
    "    # PISCO-NIK\n",
    "    model[\"PISCO\"] = {}\n",
    "    model[\"PISCO\"][\"group\"] = \"pisco\"\n",
    "    model[\"PISCO\"][\"exp\"] = (\"lamda{}_alpha0.0001___hdr0.0_slice{}_R{}\".format(l, slice, acc_factor))\n",
    "    model[\"PISCO\"][\"model_state\"] = model_state\n",
    "    \n",
    "    # PISCO-NIK-dist\n",
    "    model[\"PISCO-dist\"] = {}\n",
    "    model[\"PISCO-dist\"][\"group\"] = \"pisco-kreg-L1dist\"\n",
    "    model[\"PISCO-dist\"][\"exp\"] = (\"lamda{}_alpha0.0001___hdr0.0_slice{}_R{}\".\n",
    "                                  format(l, slice, acc_factor))\n",
    "    model[\"PISCO-dist\"][\"model_state\"] = model_state\n",
    "\n",
    "    plot_order = [\"ref\", \"nufft25\", \"xdgrasp25\", \"nik\", \"PISCO-dist\", \"PISCO\"]\n",
    "    # plot_order = [\"nufft25\", \"xdgrasp25\", \"nik\", \"PISCO-dist\", \"PISCO\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:50:59.957348300Z",
     "start_time": "2024-12-16T16:50:59.924812600Z"
    }
   },
   "id": "2e0e9d66c32c9714",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pisco model from:  /home/iml/veronika.spieker/workspace/PISCO-priv/results/checkpoints/pisco_S10/lamda0.15_alpha0.0001___hdr0.0_slice0_R104\n"
     ]
    }
   ],
   "source": [
    "results_path = os.path.join(notebook_dir, \"comparison_results_{}_slice{}_R{}\".format(sub, slice, acc_factor))  #\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "## Load further reference methods\n",
    "pisco_path = os.path.join(parent_dir, checkpoint_path, model[\"PISCO\"][\"group\"] + \"_\" + sub, model[\"PISCO\"][\"exp\"])\n",
    "pisco_exp = os.listdir(pisco_path)[0]\n",
    "config = basic.parse_config(os.path.join(pisco_path, pisco_exp, \"model_checkpoints/config.yml\"))\n",
    "\n",
    "print(\"Loading pisco model from: \", pisco_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:52:16.679111100Z",
     "start_time": "2024-12-16T16:52:16.570246100Z"
    }
   },
   "id": "49b8d1b28bf78b5b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading grasp recon from:  ['/home/iml/veronika.spieker/workspace/PISCO-priv/dummy_data/grasprecon/grasp_reference_0_25MS_R104.npz']\n"
     ]
    }
   ],
   "source": [
    "# ######### NUFFT reference #########\n",
    "######### grasp reference #########\n",
    "grasp_path = os.path.join(parent_dir, \"dummy_data/grasprecon/\")\n",
    "grasp_paths = glob.glob(grasp_path +\n",
    "                \"/grasp_reference_{}_*_R{}.npz\".format(slice, config[\"dataset\"][\"acc_factor\"]))\n",
    "\n",
    "print(\"Loading grasp recon from: \", grasp_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:52:17.983315500Z",
     "start_time": "2024-12-16T16:52:17.971010500Z"
    }
   },
   "id": "9689280ac5bdbecd",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "######### NIK reference #########\n",
    "nik_group_name = config[\"model\"][\"pretrained\"][\"pretrain_group\"] + \"_S\" + str(config[\"subject_name\"])\n",
    "nik_exp_name = (config[\"model\"][\"pretrained\"][\"pretrain_exp\"]\n",
    "                + \"*_omega\" + str(config['model']['params']['omega_0'])\n",
    "                + \"*_sigma\" +  str(config['encoding']['sigma'])\n",
    "                + \"*_hdr\" + str(config['hdr_ff_factor'])\n",
    "                + \"_slice\" + str(config[\"slice\"])\n",
    "                + \"_R\" + str(config['dataset']['acc_factor']))\n",
    "nik_group_path = basic.find_subfolder(os.path.join(parent_dir, checkpoint_path), nik_group_name)\n",
    "nik_exp_path = basic.find_subfolder(nik_group_path, nik_exp_name)\n",
    "nik_path = os.listdir(nik_exp_path)[0]\n",
    "nik = np.load(nik_exp_path + \"/\" + nik_path + '/rec_test/recon_{}.npz'.format(model_state), allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:52:30.640318Z",
     "start_time": "2024-12-16T16:52:30.586870200Z"
    }
   },
   "id": "5c53f45b10f99758",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "######### LOAD IMAGES ##############################################################################################################\n",
    "img = {}\n",
    "eval_dict = {}\n",
    "\n",
    "### GRASP\n",
    "for g in grasp_paths:\n",
    "    grasp = np.load(g, allow_pickle=True)\n",
    "    nMS = int(re.search(r'(\\d+)MS', g).group(1))\n",
    "    img[\"xdgrasp{}\".format(nMS)] = grasp[\"grasp\"][:, 0, ...].transpose(1, 0, 2, 3,4)  # from batch, ms1, ms2, z, y, x to ms, ech, z, y, x\n",
    "    img[\"xdgrasp{}\".format(nMS)] = grasp[\"grasp\"][:, 0, ...].transpose(1, 0, 2, 3,4)  # from batch, ms1, ms2, z, y, x to ms, ech, z, y, x\n",
    "    img[\"nufft{}\".format(nMS)] = grasp[\"nufft\"][:, 0, ...].transpose(1, 0, 2, 3,4)  # from batch, ms1, ms2, z, y, x to ms, ech, z, y, x\n",
    "    img[\"xdgrasp{}\".format(nMS)] = img[\"xdgrasp{}\".format(nMS)][:, [config[\"echo\"]], ...]  # select echo\n",
    "    img[\"nufft{}\".format(nMS)] = img[\"nufft{}\".format(nMS)][:, [config[\"echo\"]], ...]  # select echo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:52:34.309604500Z",
     "start_time": "2024-12-16T16:52:34.036413200Z"
    }
   },
   "id": "901611d73b3cdf80",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### NIK\n",
    "img[\"nik\"] = nik[\"recon\"]\n",
    "\n",
    "### PISCO (and all comparisons)\n",
    "paths = {}\n",
    "for key, mod in model.items():\n",
    "    temp_path = os.path.join(parent_dir, checkpoint_path, mod[\"group\"] + \"_\" + sub, mod[\"exp\"])\n",
    "    temp_exp_path = os.listdir(temp_path)[0]\n",
    "    paths[key] = os.path.join(temp_path, temp_exp_path, 'rec_test/recon_{}.npz'.format(mod[\"model_state\"]))\n",
    "    img[key] = np.load(paths[key], allow_pickle=True)[\"recon\"]\n",
    "\n",
    "\n",
    "#'' Save comparison files in path to traceback\n",
    "paths[\"NIK\"] = nik_exp_path\n",
    "paths[\"GRASP\"] = grasp_path\n",
    "with open(os.path.join(results_path, \"paths.txt\"), \"w\") as f:\n",
    "    json.dump(model, f, indent=4)\n",
    "    f.write(\"\\n Model Settings\")\n",
    "    json.dump(paths, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:52:39.984370200Z",
     "start_time": "2024-12-16T16:52:39.936707300Z"
    }
   },
   "id": "e0acf9b10dbc6b79",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "######### EVALUATE ################################################################################################################\n",
    "### Define reference\n",
    "if config[\"data_type\"] == \"knee\":\n",
    "    ref_file = \"grasp_reference_{}_1MS_R1.npz\".format(config[\"slice\"])\n",
    "    img[\"ref\"] = np.load(os.path.join(os.path.dirname(grasp_paths[0]), ref_file))[\"nufft\"][...,0,:,:].transpose(2,0,1,3,4) # add\n",
    "    img[\"ref\"] = img[\"ref\"][:, [config[\"echo\"]], ...] # select echo\n",
    "    # img[\"ref\"] = grasp[\"R1\"].item()[\"INUFFTnufft\"].repeat(100,1,1,1,1) #  grasp[\"R{}\".format(acc_factor)].item()[\"INUFFTnufft\"].repeat(100,1,1,1,1)\n",
    "elif config[\"data_type\"] == \"abdominal_sos\":\n",
    "    ref_file = \"grasp_reference_{}_1MS_R1.npz\".format(config[\"slice\"]) # ToDo: decide for reference here?\n",
    "    img[\"ref\"] = np.load(os.path.join(os.path.dirname(grasp_paths[0]), ref_file))[\"nufft\"][...,0,:,:].transpose(2,0,1,3,4)\n",
    "    img[\"ref\"] = img[\"ref\"].repeat(100,0)[:, [config[\"echo\"]], ...]\n",
    "elif config[\"data_type\"] == \"cardiac_cine\":\n",
    "    ref_file = \"grasp_reference_{}_25MS_R1.npz\".format(config[\"slice\"])\n",
    "    img[\"ref\"] = np.load(os.path.join(os.path.dirname(grasp_paths[0]), ref_file))[\"grasp\"][...,0,:,:].transpose(2,0,1,3,4)\n",
    "else:\n",
    "    AssertionError(\"Invalid data type: {}\".format(config[\"data_type\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:52:40.531087200Z",
     "start_time": "2024-12-16T16:52:40.509665100Z"
    }
   },
   "id": "908a885813f6bb44",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### PostProcess\n",
    "# Crop all images to reference\n",
    "import utils.mri\n",
    "img[\"ref\"] = utils.mri.center_crop(img[\"ref\"], [config[\"final_shape\"], config[\"final_shape\"]])\n",
    "for i in img.keys():\n",
    "    if i != \"ref\":\n",
    "        img[i] = utils.mri.center_crop(img[i], img[\"ref\"].shape[-2:])\n",
    "# Rescale\n",
    "for key in img.keys():\n",
    "    img[key] = basic.torch2numpy(img[key])\n",
    "    img[key] = np.abs(img[key])\n",
    "    if config[\"data_type\"] in [\"abdominal_phantom\", \"abdominal_phantom_nohist\"]:\n",
    "        if img[key].shape[0]!= img[\"ref\"].shape[0]:\n",
    "            img[key] = eval.create_hystereses(img[key], dim_axis=0)\n",
    "    elif config[\"data_type\"] in [\"abdominal_sos\"]:\n",
    "        img[key] = eval.create_hystereses(img[key], dim_axis=0)\n",
    "    img[key] = eval.postprocess(img[key], img[\"ref\"])\n",
    "\n",
    "## cutoff hysteresis (if no hysteresis considered then inhale=exhale -> process/plot only half)\n",
    "if config[\"data_type\"] in [\"abdominal_sos\"]:\n",
    "    for key in img.keys():\n",
    "        cutoff = (img[key].shape[0] // 2)\n",
    "        img[key] = img[key][:cutoff, ...]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:52:42.095619Z",
     "start_time": "2024-12-16T16:52:42.028556200Z"
    }
   },
   "id": "311ed6cb146e2e1b",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "ssim : 0.609\n",
      "ssim_std : 0.042\n",
      "psnr : 19.158\n",
      "psnr_std : 0.76\n",
      "rmse : 0.329\n",
      "rmse_std : 0.034\n",
      "fsim : 0.641\n",
      "fsim_std : 0.015\n",
      "lpips_alex : 0.144\n",
      "lpips_alex_std : 0.018\n",
      "lpips_vgg : 0.309\n",
      "lpips_vgg_std : 0.022\n",
      "fsim_xt : 0.487\n",
      "fsim_xt_std : 0.047\n",
      "fsim_yt : 0.491\n",
      "fsim_yt_std : 0.035\n",
      "lpips_xt_alex : 0.069\n",
      "lpips_xt_alex_std : 0.025\n",
      "lpips_yt_alex : 0.078\n",
      "lpips_yt_alex_std : 0.03\n",
      "lpips_xt_vgg : 0.199\n",
      "lpips_xt_vgg_std : 0.03\n",
      "lpips_yt_vgg : 0.197\n",
      "lpips_yt_vgg_std : 0.03\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "ssim : 0.171\n",
      "ssim_std : 0.022\n",
      "psnr : 12.911\n",
      "psnr_std : 0.962\n",
      "rmse : 0.677\n",
      "rmse_std : 0.081\n",
      "fsim : 0.427\n",
      "fsim_std : 0.026\n",
      "lpips_alex : 0.344\n",
      "lpips_alex_std : 0.049\n",
      "lpips_vgg : 0.532\n",
      "lpips_vgg_std : 0.008\n",
      "fsim_xt : 0.34\n",
      "fsim_xt_std : 0.039\n",
      "fsim_yt : 0.321\n",
      "fsim_yt_std : 0.044\n",
      "lpips_xt_alex : 0.317\n",
      "lpips_xt_alex_std : 0.04\n",
      "lpips_yt_alex : 0.329\n",
      "lpips_yt_alex_std : 0.057\n",
      "lpips_xt_vgg : 0.547\n",
      "lpips_xt_vgg_std : 0.025\n",
      "lpips_yt_vgg : 0.545\n",
      "lpips_yt_vgg_std : 0.026\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "ssim : 0.335\n",
      "ssim_std : 0.015\n",
      "psnr : 17.331\n",
      "psnr_std : 0.18\n",
      "rmse : 0.404\n",
      "rmse_std : 0.014\n",
      "fsim : 0.559\n",
      "fsim_std : 0.008\n",
      "lpips_alex : 0.459\n",
      "lpips_alex_std : 0.018\n",
      "lpips_vgg : 0.468\n",
      "lpips_vgg_std : 0.007\n",
      "fsim_xt : 0.419\n",
      "fsim_xt_std : 0.053\n",
      "fsim_yt : 0.42\n",
      "fsim_yt_std : 0.06\n",
      "lpips_xt_alex : 0.174\n",
      "lpips_xt_alex_std : 0.072\n",
      "lpips_yt_alex : 0.133\n",
      "lpips_yt_alex_std : 0.045\n",
      "lpips_xt_vgg : 0.249\n",
      "lpips_xt_vgg_std : 0.033\n",
      "lpips_yt_vgg : 0.257\n",
      "lpips_yt_vgg_std : 0.038\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "ssim : 0.649\n",
      "ssim_std : 0.019\n",
      "psnr : 20.548\n",
      "psnr_std : 0.396\n",
      "rmse : 0.28\n",
      "rmse_std : 0.019\n",
      "fsim : 0.655\n",
      "fsim_std : 0.009\n",
      "lpips_alex : 0.123\n",
      "lpips_alex_std : 0.009\n",
      "lpips_vgg : 0.265\n",
      "lpips_vgg_std : 0.01\n",
      "fsim_xt : 0.512\n",
      "fsim_xt_std : 0.053\n",
      "fsim_yt : 0.528\n",
      "fsim_yt_std : 0.034\n",
      "lpips_xt_alex : 0.056\n",
      "lpips_xt_alex_std : 0.029\n",
      "lpips_yt_alex : 0.061\n",
      "lpips_yt_alex_std : 0.021\n",
      "lpips_xt_vgg : 0.162\n",
      "lpips_xt_vgg_std : 0.027\n",
      "lpips_yt_vgg : 0.169\n",
      "lpips_yt_vgg_std : 0.028\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/iml/veronika.spieker/anaconda3/envs/pisco_nik/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "ssim : 0.388\n",
      "ssim_std : 0.016\n",
      "psnr : 18.254\n",
      "psnr_std : 0.196\n",
      "rmse : 0.364\n",
      "rmse_std : 0.013\n",
      "fsim : 0.586\n",
      "fsim_std : 0.011\n",
      "lpips_alex : 0.369\n",
      "lpips_alex_std : 0.017\n",
      "lpips_vgg : 0.432\n",
      "lpips_vgg_std : 0.01\n",
      "fsim_xt : 0.438\n",
      "fsim_xt_std : 0.051\n",
      "fsim_yt : 0.44\n",
      "fsim_yt_std : 0.059\n",
      "lpips_xt_alex : 0.154\n",
      "lpips_xt_alex_std : 0.068\n",
      "lpips_yt_alex : 0.119\n",
      "lpips_yt_alex_std : 0.045\n",
      "lpips_xt_vgg : 0.232\n",
      "lpips_xt_vgg_std : 0.032\n",
      "lpips_yt_vgg : 0.242\n",
      "lpips_yt_vgg_std : 0.036\n"
     ]
    }
   ],
   "source": [
    "## Compute metrics\n",
    "ech = 0\n",
    "eval_str_xy, eval_str_xt, eval_str_yt = {},{},{}\n",
    "img_diff = {}\n",
    "for key in img.keys():\n",
    "    if key != \"ref\":\n",
    "        if config[\"data_type\"] in [\"abdominal_phantom\", \"abdominal_phantom_nohist\", \"cardiac_cine\", \"knee\"]:\n",
    "            eval_dict[key] = eval.get_eval_metrics(img[key][:,ech, ...], img[\"ref\"][:, ech,  ...])\n",
    "        elif \"11_R0\" in sub:\n",
    "            eval_dict[key] = eval.get_eval_metrics(img[key][[0], ech, ...], img[\"ref\"][[t], ech, ...]) # calculate metric only for temproal value\n",
    "        eval_str_xy[key] = eval.make_string_from_value_dict(eval_dict[key], default_keys=[\"psnr\", \"fsim\"])\n",
    "        eval_str_xt[key] = eval.make_string_from_value_dict(eval_dict[key], default_keys=[\"fsim_xt\"])\n",
    "        eval_str_yt[key] = eval.make_string_from_value_dict(eval_dict[key], default_keys=[\"fsim_yt\"])\n",
    "\n",
    "        img_diff[key] = np.abs(img[key] - img[\"ref\"]).squeeze(1).squeeze(1)\n",
    "\n",
    "    img_diff[\"ref\"] = np.zeros_like(img[\"ref\"]).squeeze(1).squeeze(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:53:32.933951600Z",
     "start_time": "2024-12-16T16:52:42.857062100Z"
    }
   },
   "id": "688d85e38ab1bdc2",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import medutils\n",
    "img_sat, img_nosat, img_diff_plot = {}, {}, {}\n",
    "for key in plot_order:\n",
    "    img_nosat[key] = medutils.visualization.contrastStretching(img[key][...].squeeze(1).squeeze(1), saturated_pixel=0.00)\n",
    "    img_nosat[key] /= 255.0\n",
    "    img_diff_plot[key] = img_diff[key]\n",
    "    img_sat[key] = medutils.visualization.contrastStretching(img[key][...].squeeze(1).squeeze(1), saturated_pixel=0.04)\n",
    "    img_sat[key] /= 255.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:53:33.086850100Z",
     "start_time": "2024-12-16T16:53:32.919944Z"
    }
   },
   "id": "be71aeb46e443ca3",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "t = 10\n",
    "x = img[\"ref\"].shape[-2] // 2 + 2  # to avoid center point\n",
    "y = img[\"ref\"].shape[-1] // 2 + 2  # to avoid center point\n",
    "\n",
    "if config[\"data_type\"] == \"cardiac_cine\" and config[\"subject_name\"] == 10:\n",
    "    for key in img_nosat.keys():\n",
    "        img_nosat[key] = np.flip(img_nosat[key], axis=2)\n",
    "        if key != \"ref\":\n",
    "            img_diff_plot[key] = np.flip(img_diff_plot[key], axis=2)\n",
    "\n",
    "\n",
    "print(\"Example reconstruction for subject {} at R={} and slice {}\".format(sub, acc_factor, slice))\n",
    "vis.plot_3d_slices_from_dict(img_nosat, t=t, x=x, fontsize=14,\n",
    "                             eval_str_dict={\"t\": eval_str_xy,  \"x\": eval_str_xt},\n",
    "                             results_path=results_path + \"/recon_comp_3d_slices_t{}_x{}_y{}.eps\".format(t, x, y),\n",
    "                             cmap=\"gray\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-16T16:51:00.558112700Z"
    }
   },
   "id": "d11136dfd7aac66",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
